NAME: Alex Yu
EMAIL: alexy23@g.ucla.edu
ID: 105295708

The following files are included:
* lab2_list.c is a C program that implements shared doubly linked-list functions with yield and synchronization options
* lab2_list.gp is a gnuplot data reduction script used to generate graphs for lab2_list
* lab2b_list.csv is a csv file that contains all of the data generated from lab2_list tests
* lab2b_1.png, lab2b_2.png, lab2b_3.png, lab2b_4.png, and lab2b_5.png are graphs generated using data from the 
lab2_list tests
* SortedList.h, SortedList.c are a header file and a C module that define and implement doubly linked-lists
* profile.out is an execution profiling report of where time was spent in the un-partitioned spin-lock implementation
* Makefile provides targets to build, test, plot data, and clean up the program(s)
* test.sh is a script that tests lab2_add and lab2_list and stores the results in the csv files
* README is a text file that documents the included files and provides answers to the questions from the spec

QUESTION 2.3.1 - Cycles in the basic list implementation:
    Where do you believe most of the cycles are spent in the 1 and 2-thread list tests ?

    Why do you believe these to be the most expensive parts of the code?

    Where do you believe most of the time/cycles are being spent in the high-thread spin-lock tests?

    Where do you believe most of the time/cycles are being spent in the high-thread mutex tests?

QUESTION 2.3.2 - Execution Profiling:
    Where (what lines of code) are consuming most of the cycles when the spin-lock version of the list exerciser is run with a large number of threads?

    Why does this operation become so expensive with large numbers of threads?

QUESTION 2.3.3 - Mutex Wait Time:
    Look at the average time per operation (vs. # threads) and the average wait-for-mutex time (vs. #threads).
    Why does the average lock-wait time rise so dramatically with the number of contending threads?
    Why does the completion time per operation rise (less dramatically) with the number of contending threads?
    How is it possible for the wait time per operation to go up faster (or higher) than the completion time per operation?

QUESTION 2.3.4 - Performance of Partitioned Lists
    Explain the change in performance of the synchronized methods as a function of the number of lists.
    Should the throughput continue increasing as the number of lists is further increased? If not, explain why not.
    It seems reasonable to suggest the throughput of an N-way partitioned list should be equivalent to the throughput of a single list with fewer (1/N) threads. Does this appear to be true in the above curves? If not, explain why not.
